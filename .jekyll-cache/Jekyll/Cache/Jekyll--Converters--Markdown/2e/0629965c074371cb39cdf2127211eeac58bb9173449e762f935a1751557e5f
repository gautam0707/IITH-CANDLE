I"X"<p><a href="https://arxiv.org/abs/1234.56789"><img src="https://img.shields.io/badge/arXiv-1234.56789-b31b1b.svg" alt="arXiv" /></a>
<a href="https://aaai.org/Conferences/AAAI-22/"><img src="https://img.shields.io/badge/AAAI 2022-&lt;identifier&gt;-275161.svg" alt="AAAI" /></a>
<a href="https://drive.google.com/drive/folders/11w267LWI8tbWhf1SR8kd-l6fP9WbJwNL"><img src="https://img.shields.io/badge/Get%20the%20Dataset-4285F4?logo=googledrive&amp;logoColor=white" alt="Get the dataset" /></a>
<a href="https://github.com/causal-disentanglement/IITH-CANDLE/blob/main/LICENSE"><img src="https://img.shields.io/github/license/causal-disentanglement/IITH-CANDLE" alt="GitHub" /></a></p>

<p><a href="https://iith.ac.in"><img align="right" height="100px" style="margin-left: 10px" src="./images/iith.png" /></a>
<a href="https://lab1055.github.io"><img align="right" height="100px" style="margin-left: 10px" src="./images/lab1055.png" /></a></p>

<p>The CANDLE dataset contains 12546 images in <code class="language-plaintext highlighter-rouge">.png</code> format. Each image is rendered by randomly placing a foreground object in a background scene. Generating images in a controlled manner allows for recording the ground truth factors of variation and hence allows us to study disentangled representation learning using both unsupervised and supvervised learning.</p>

<h1 id="factors-of-variation">Factors of Variation</h1>
<p>CANDLE dataset is generated by following the data generating mechanism detailed below. All generative factors are self explanatory. $U$ denotes an unobserved confounder, viz. the subtle interactions between the <em>scene</em>’s natural light and the external <em>light</em> factor. $C$ denotes any observed confounder which is responsible for spurious correlations in data. Values taken by each of the generative factors in the causal graph are listed in the table below.</p>

<p align="center">
  <img width="460" src="./images/datagenerator.png" />
</p>

<table>
  <thead>
    <tr>
      <th>Generative Factor</th>
      <th>Possible Values</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Object</td>
      <td>Cube, Sphere, Cylinder, Cone, Torus</td>
    </tr>
    <tr>
      <td>Color</td>
      <td>Red, Blue, Yellow, Purple, Orange</td>
    </tr>
    <tr>
      <td>Size</td>
      <td>Small, Medium, Large</td>
    </tr>
    <tr>
      <td>Rotation</td>
      <td>0◦, 15◦, 30◦, 45◦, 60◦, 90◦</td>
    </tr>
    <tr>
      <td>Light</td>
      <td>Left, Middle, Right</td>
    </tr>
    <tr>
      <td>Scene</td>
      <td>Indoor, Playground, Outdoor, Bridge, City Square, Hall, Grassland, Garage, Street, Beach, Station, Tunnel, Moonlit Grass, Dusk City, Skywalk, Garden</td>
    </tr>
  </tbody>
</table>

<h1 id="structure-of-the-ground-truth-metadata">Structure of the ground-truth metadata</h1>
<p>Ground truth information for each image in the dataset is provided in <code class="language-plaintext highlighter-rouge">json</code> format. Below is a sample image and its corresponding meta data.</p>

<p><img align="right" height="275px" style="margin-left: 10px" src="./images/3541.png" /></p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nl">"scene"</span><span class="p">:</span><span class="w"> </span><span class="s2">"playground"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"lights"</span><span class="p">:</span><span class="w"> </span><span class="s2">"middle"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"objects"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"Torus_0"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
            </span><span class="nl">"object_type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"torus"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"color"</span><span class="p">:</span><span class="w"> </span><span class="s2">"blue"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"size"</span><span class="p">:</span><span class="w"> </span><span class="mf">2.5</span><span class="p">,</span><span class="w">
            </span><span class="nl">"rotation"</span><span class="p">:</span><span class="w"> </span><span class="mi">15</span><span class="p">,</span><span class="w">
            </span><span class="nl">"bounds"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                </span><span class="p">[</span><span class="mi">150</span><span class="p">,</span><span class="mi">36</span><span class="p">],</span><span class="w">
                </span><span class="p">[</span><span class="mi">245</span><span class="p">,</span><span class="mi">66</span><span class="p">]</span><span class="w">
            </span><span class="p">]</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h1 id="downloading-candle">Downloading CANDLE</h1>
<p>The dataset can be downloaded from <a href="https://drive.google.com/drive/folders/11w267LWI8tbWhf1SR8kd-l6fP9WbJwNL">here</a> (1.7 GB).</p>

<h1 id="simulating-and-extending-candle">Simulating and extending CANDLE</h1>
<p>CANDLE is rendered using <a href="https://www.blender.org">Blender</a> by overlaying 3D sprites on panoramic HDRi background images. Simulating a version is as simple as running <code class="language-plaintext highlighter-rouge">blender -b -noaudio -P candle_simulator.py</code>.</p>

<p>Don’t like the torus? Want a monkey there instead? Simply create the sprites and add them to the simulator. Code and instructions are at <a href="https://github.com/causal-disentanglement/candle-simulator">the candle-simulator repository</a>.</p>

<h1 id="evaluation-metrics">Evaluation Metrics</h1>
<p>We also propose two evaluation metrics in our paper to study <em>causal disentanglement</em>. We look at latent variable models (e.g., Beta VAE) as disentangled causal processes (Suter et al, ICML 2019) and propose two evaluation metrics to measure causal disentanglement using the notion of causally responsible generative factors in an image. Please refer to the paper for more details.</p>

<h1 id="experiments">Experiments</h1>
<p>The code and instructions to reproduce experiments in the paper can be found at (a fork of) <a href="https://github.com/causal-disentanglement/disentanglement_lib">disentanglement_lib</a>.</p>

<h1 id="abstract">Abstract</h1>
<p>Representation learners that disentangle factors of variation have already proven to be important in addressing various real world concerns such as fairness and interpretability. Initially consisting of unsupervised models with independence assumptions, more recently, weak supervision and correlated features have been explored, but without a causal view of the generative process. In contrast, we work under the regime of a causal generative process where generative factors are either independent or can be potentially confounded by a set of observed or unobserved confounders. We present an analysis of disentangled representations through the notion of disentangled causal process. We motivate the need for new metrics and datasets to study causal disentanglement and propose two evaluation metrics and a dataset. We show that our metrics capture the desiderata of disentangled causal process. Finally, we perform an empirical study on state of the art disentangled representation learners using our metrics and dataset to evaluate them from causal perspective.</p>

<h1 id="paper-pdf">Paper PDF</h1>
<p>AAAI version of the paper can be viewed <a href="https://arxiv.org/">here</a>.</p>

<p>An arXiv preprint is also available <a href="https://arxiv.org/">here</a>.</p>

<h1 id="how-to-cite-our-work">How to cite our work</h1>
<p>If you use <em>CANDLE</em>, please consider citing:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{candle, 
title={On Causally Disentangled Representations},  
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
author={Abbavaram Gowtham Reddy, Benin Godfrey L, and Vineeth N Balasubramanian}, 
year={2022},
month={February}
}
</code></pre></div></div>

<h1 id="license">License</h1>
<p>This work is licensed under the <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</p>
:ET